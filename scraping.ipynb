{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nba_api\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install lxml  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from os import getcwd,makedirs,listdir\n",
    "from os.path import dirname\n",
    "from os.path import exists\n",
    "from nba_api.stats.endpoints import playercareerstats,leaguedashptdefend,leaguedashptstats,leaguedashplayerbiostats,leaguehustlestatsplayer, playerdashptreb,leaguedashplayerstats\n",
    "\n",
    "path = getcwd()\n",
    "parent = dirname(path)\n",
    "DIR_DATA = parent+'/data/'\n",
    "DIR_RAW_DATA = DIR_DATA+'raw/'\n",
    "DIR_CLEAN_DATA = DIR_DATA+'clean/'\n",
    "\n",
    "date_start,date_end = '2010-10-10','2022-08-01',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes about the NBA api\n",
    "- If season not specified, then it assumes the latest season is the\n",
    "- If player or team parameter not specified, assumes team is the\n",
    "- If season_type_all_star not specified, assumes Regular Season\n",
    "- Data received from the api has a little margin of difference comparing to what is on the official website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1378\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\requests\\adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 440\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    441\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    442\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    443\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    444\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    445\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    446\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    447\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    448\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    449\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    450\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    453\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    783\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 785\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    786\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    787\u001b[0m )\n\u001b[0;32m    788\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[0;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 770\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[0;32m    771\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:451\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_timeout(err\u001b[39m=\u001b[39;49me, url\u001b[39m=\u001b[39;49murl, timeout_value\u001b[39m=\u001b[39;49mread_timeout)\n\u001b[0;32m    452\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:340\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    341\u001b[0m         \u001b[39mself\u001b[39m, url, \u001b[39m\"\u001b[39m\u001b[39mRead timed out. (read timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m timeout_value\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    344\u001b[0m \u001b[39m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\esrpi\\Documents\\pedro\\faculdade\\mestrado\\2y\\IACH\\nba-injury-prediction\\scraping.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/esrpi/Documents/pedro/faculdade/mestrado/2y/IACH/nba-injury-prediction/scraping.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m player_common_stats_df \u001b[39m=\u001b[39m leaguedashplayerstats\u001b[39m.\u001b[39;49mLeagueDashPlayerStats(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esrpi/Documents/pedro/faculdade/mestrado/2y/IACH/nba-injury-prediction/scraping.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         season \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m2019-20\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esrpi/Documents/pedro/faculdade/mestrado/2y/IACH/nba-injury-prediction/scraping.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                         per_mode_detailed\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPerGame\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esrpi/Documents/pedro/faculdade/mestrado/2y/IACH/nba-injury-prediction/scraping.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                         league_id_nullable \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m00\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esrpi/Documents/pedro/faculdade/mestrado/2y/IACH/nba-injury-prediction/scraping.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                         season_type_all_star\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mRegular Season\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mget_data_frames()[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esrpi/Documents/pedro/faculdade/mestrado/2y/IACH/nba-injury-prediction/scraping.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m player_common_stats_df\u001b[39m.\u001b[39minfo()\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\nba_api\\stats\\endpoints\\leaguedashplayerstats.py:100\u001b[0m, in \u001b[0;36mLeagueDashPlayerStats.__init__\u001b[1;34m(self, last_n_games, measure_type_detailed_defense, month, opponent_team_id, pace_adjust, per_mode_detailed, period, plus_minus, rank, season, season_type_all_star, college_nullable, conference_nullable, country_nullable, date_from_nullable, date_to_nullable, division_simple_nullable, draft_pick_nullable, draft_year_nullable, game_scope_simple_nullable, game_segment_nullable, height_nullable, league_id_nullable, location_nullable, outcome_nullable, po_round_nullable, player_experience_nullable, player_position_abbreviation_nullable, season_segment_nullable, shot_clock_range_nullable, starter_bench_nullable, team_id_nullable, two_way_nullable, vs_conference_nullable, vs_division_nullable, weight_nullable, proxy, headers, timeout, get_request)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters \u001b[39m=\u001b[39m {\n\u001b[0;32m     62\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mLastNGames\u001b[39m\u001b[39m'\u001b[39m: last_n_games,\n\u001b[0;32m     63\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMeasureType\u001b[39m\u001b[39m'\u001b[39m: measure_type_detailed_defense,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mWeight\u001b[39m\u001b[39m'\u001b[39m: weight_nullable\n\u001b[0;32m     98\u001b[0m }\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m get_request:\n\u001b[1;32m--> 100\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_request()\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\nba_api\\stats\\endpoints\\leaguedashplayerstats.py:103\u001b[0m, in \u001b[0;36mLeagueDashPlayerStats.get_request\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_request\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnba_response \u001b[39m=\u001b[39m NBAStatsHTTP()\u001b[39m.\u001b[39;49msend_api_request(\n\u001b[0;32m    104\u001b[0m         endpoint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint,\n\u001b[0;32m    105\u001b[0m         parameters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters,\n\u001b[0;32m    106\u001b[0m         proxy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproxy,\n\u001b[0;32m    107\u001b[0m         headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    108\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    109\u001b[0m     )\n\u001b[0;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_response()\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\nba_api\\library\\http.py:130\u001b[0m, in \u001b[0;36mNBAHTTP.send_api_request\u001b[1;34m(self, endpoint, parameters, referer, proxy, headers, timeout, raise_exception_on_error)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloading from file...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m contents:\n\u001b[1;32m--> 130\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url\u001b[39m=\u001b[39;49mbase_url, params\u001b[39m=\u001b[39;49mparameters, headers\u001b[39m=\u001b[39;49mrequest_headers, proxies\u001b[39m=\u001b[39;49mproxies, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    131\u001b[0m     url \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39murl\n\u001b[0;32m    132\u001b[0m     status_code \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\requests\\api.py:75\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39m\u001b[39mget\u001b[39m\u001b[39m'\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[0;32m    527\u001b[0m }\n\u001b[0;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\esrpi\\anaconda3\\lib\\site-packages\\requests\\adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    531\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[1;32m--> 532\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    533\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[0;32m    534\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidHeader(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)"
     ]
    }
   ],
   "source": [
    "player_common_stats_df = leaguedashplayerstats.LeagueDashPlayerStats(\n",
    "                        season = '2019-20',\n",
    "                        per_mode_detailed='PerGame',\n",
    "                        league_id_nullable = '00',\n",
    "                        season_type_all_star= 'Regular Season').get_data_frames()[0]\n",
    "player_common_stats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrer_defend = leaguedashptdefend.LeagueDashPtDefend(\n",
    "                season = '2020-21',\n",
    "                per_mode_simple='PerGame',\n",
    "                defense_category='Overall',\n",
    "                league_id = '00',\n",
    "                season_type_all_star = 'Regular Season')\n",
    "\n",
    "carrer_defend.get_data_frames()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bio = leaguedashplayerbiostats.LeagueDashPlayerBioStats(\n",
    "                season = '2020-21',\n",
    "                per_mode_simple='PerGame',\n",
    "                league_id = '00',\n",
    "                season_type_all_star= 'Regular Season').get_data_frames()[0]\n",
    "df_bio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_distance_player = leaguedashptstats.LeagueDashPtStats(\n",
    "                            season = '2019-20',\n",
    "                            season_type_all_star = 'Regular Season',\n",
    "                            per_mode_simple = 'PerGame',\n",
    "                            player_or_team = 'Player',\n",
    "                            # month = ,\n",
    "                            ).get_data_frames()[0]\n",
    "speed_distance_player.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hustle_player = leaguehustlestatsplayer.LeagueHustleStatsPlayer(\n",
    "                            season = '2019-20',\n",
    "                            season_type_all_star = 'Regular Season',\n",
    "                            per_mode_time = 'PerGame',\n",
    "                            # month = ,\n",
    "                            )\n",
    "\n",
    "hustle_player.get_data_frames()[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hustle_player.get_data_frames()[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reb_player = playerdashptreb.PlayerDashPtReb(\n",
    "                            season = '2019-20',\n",
    "                            season_type_all_star = 'Regular Season',\n",
    "                            per_mode_simple = 'PerGame',\n",
    "                            player_id= '203932',\n",
    "                            team_id = '1610612753'\n",
    "                            )\n",
    "reb_player.get_data_frames()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reb_player.get_data_frames()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reb_player.get_data_frames()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA API Data\n",
    "\n",
    "**Observations**\n",
    "- Some endpoints have **month** parameter others don't\n",
    "- Existent duplicate record (e.g 201147) \n",
    "- Difference in height won't make a difference, most of the players maintain their height since it's a biological thing and its out of the control of athletes\n",
    "- Difficulty in joining data in a interval of time beacuse new players come in every season as well some retire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping\n",
    "\n",
    "Data scraped from the nba stats official site using the nba_api package:\n",
    "\n",
    "- [LeagueDashPlayerBioStats](https://github.com/swar/nba_api/blob/master/docs/nba_api/stats/endpoints/leaguedashplayerbiostats.md)\n",
    "    - Season - Year of the season\n",
    "    - GP - Games played in segment\n",
    "    - PLAYER_HEIGHT_INCHES- player height in inches\n",
    "    - PLAYER_WEIGHT- player weight in pounds\n",
    "    - AGE- age of player\n",
    "- [LeagueDashPtDefend](https://github.com/swar/nba_api/blob/master/docs/nba_api/stats/endpoints/leaguedashptdefend.md)\n",
    "    - D_FG_A: The number of opponents shots attempted when a player or team is defending the shot\n",
    "- [LeagueDashPtStats](https://github.com/swar/nba_api/blob/master/docs/nba_api/stats/endpoints/leaguedashptstats.md)\n",
    "    - DIST_MILES: Distance run by a player or team measured in miles\n",
    "    - DIST_MILES_OFF: in offense\n",
    "    - DIST_MILES_DEF: in defense\n",
    "    - AVG_SPEED: speed of how many miles the player can run per second\n",
    "    - AVG_SPEED_OFF: in offense\n",
    "    - AVG_SPEED_DEF: in defense\n",
    "- [LeagueHustleStatsPlayer](https://github.com/swar/nba_api/blob/master/docs/nba_api/stats/endpoints/leaguehustlestatsplayer.md)\n",
    "    - CONTESTED_SHOTS:\n",
    "    - CONTESTED_SHOTS_2\n",
    "    - CONTESTED_SHOT_3\n",
    "    - DEFLECTIONS: The number of times a defensive player or team gets their hand on the ball on a non-shot attempt\n",
    "    - CHARGES_DRAWN: The number of times a defensive player or team draws a charge\n",
    "- [LeagueDashPlayerStats](https://github.com/swar/nba_api/blob/master/docs/nba_api/stats/endpoints/leaguedashplayerstats.md)\n",
    "    - MIN\n",
    "    - REB\n",
    "    - OREB\n",
    "    - DREB\n",
    "    - BLK: A block occurs when an offensive player attempts a shot, and the defense player tips the ball, blocking their chance to score\n",
    "    - PF: The number of personal fouls a player or team committed\n",
    "    - PFD: The number of personal fouls that are drawn by a player or team\n",
    "- POST UP PLAYS NUMBER???\n",
    "\n",
    "Problems:\n",
    "- playerstatsreb can only done player by player threfore requesting multiple times the API will crash\n",
    "\n",
    "NBA stats glossary source [here](https://www.nba.com/stats/help/glossary#dfgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dist = ['DIST_MILES','DIST_MILES_OFF','DIST_MILES_DEF']\n",
    "cols_speed = ['AVG_SPEED','AVG_SPEED_OFF','AVG_SPEED_DEF']\n",
    "cols_contested  = ['CONTESTED_SHOTS','CONTESTED_SHOTS_2PT','CONTESTED_SHOTS_3PT']\n",
    "cols_boxouts = ['BOX_OUTS','OFF_BOXOUTS','DEF_BOXOUTS']\n",
    "cols_defend = ['D_FG_PCT','D_FGA']\n",
    "cols_blocks = ['BLK']\n",
    "cols_fouls = ['PF','PFD']\n",
    "cols_rebound = ['REB','OREB','DREB']\n",
    "\n",
    "def scrape_season(year,season_format,league_id,season_type,per_mode):\n",
    "\n",
    "    if season_type == 'regular':\n",
    "        season_type_format = 'Regular Season'\n",
    "    elif season_type == 'post':\n",
    "        season_type_format = 'Playoffs'\n",
    "    elif season_type == 'all-star': \n",
    "        season_type_format = 'All Star'\n",
    "    elif season_type == 'pre':\n",
    "        season_type_format = 'Pre Season'\n",
    "    \n",
    "    if per_mode == 'total':\n",
    "        per_mode_format = 'Totals'\n",
    "    elif per_mode == 'game':\n",
    "        per_mode_format = 'PerGame'\n",
    "\n",
    "    \n",
    "    player_stats_df = leaguedashplayerbiostats.LeagueDashPlayerBioStats(\n",
    "                season = season_format,\n",
    "                per_mode_simple=per_mode_format,\n",
    "                league_id = league_id,\n",
    "                season_type_all_star= season_type_format).get_data_frames()[0]\n",
    "\n",
    "    player_stats_df = player_stats_df.drop(columns = ['PLAYER_HEIGHT','COLLEGE','COUNTRY','DRAFT_ROUND','DRAFT_NUMBER','DRAFT_YEAR','OREB_PCT',\n",
    "                                                    'DREB_PCT','USG_PCT','TS_PCT','AST_PCT','PTS','REB','AST','NET_RATING'])\n",
    "\n",
    "    player_common_stats_df = leaguedashplayerstats.LeagueDashPlayerStats(\n",
    "                        season = season_format,\n",
    "                        per_mode_detailed=per_mode_format,\n",
    "                        league_id_nullable = league_id,\n",
    "                        season_type_all_star= season_type_format).get_data_frames()[0]\n",
    "\n",
    "    cols_to_merge = ['PLAYER_ID','MIN']+cols_rebound+cols_blocks + cols_fouls\n",
    "    player_stats_df = player_stats_df.merge(player_common_stats_df[cols_to_merge],on=['PLAYER_ID'])\n",
    "\n",
    "    # defend_df = leaguedashptdefend.LeagueDashPtDefend(\n",
    "    #             season = season_format,\n",
    "    #             per_mode_simple=per_mode_format,\n",
    "    #             defense_category='Overall',\n",
    "    #             league_id = league_id,\n",
    "    #             season_type_all_star = season_type_format).get_data_frames()[0]\n",
    "\n",
    "    # defend_df = defend_df.drop(columns = ['FREQ','G','PCT_PLUSMINUS','NORMAL_FG_PCT'])\n",
    "    # defend_df = defend_df.rename(columns = {'CLOSE_DEF_PERSON_ID':'PLAYER_ID'})\n",
    "    \n",
    "    # cols_to_merge = ['PLAYER_ID'] + cols_defend\n",
    "\n",
    "    # player_stats_df = player_stats_df.merge(defend_df[cols_to_merge],on=['PLAYER_ID'])\n",
    "\n",
    "    speed_distance_data = leaguedashptstats.LeagueDashPtStats(\n",
    "                            season = season_format,\n",
    "                            season_type_all_star = season_type_format,\n",
    "                            per_mode_simple = per_mode_format,\n",
    "                            player_or_team = 'Player',\n",
    "                            ).get_data_frames()[0]\n",
    "    cols_to_merge = ['PLAYER_ID']+cols_dist+cols_speed\n",
    "\n",
    "    player_stats_df = player_stats_df.merge(speed_distance_data[cols_to_merge],on=['PLAYER_ID'])\n",
    "    \n",
    "    touches_data = 0\n",
    "    \n",
    "    hustle_data = leaguehustlestatsplayer.LeagueHustleStatsPlayer(\n",
    "                            season = season_format,\n",
    "                            season_type_all_star = season_type_format,\n",
    "                            league_id_nullable = league_id,\n",
    "                            per_mode_time = per_mode_format,\n",
    "                            ).get_data_frames()[0]\n",
    "    \n",
    "\n",
    "    cols_to_merge = ['PLAYER_ID'] + cols_contested+cols_boxouts+['DEFLECTIONS','CHARGES_DRAWN']\n",
    "\n",
    "    player_stats_df = player_stats_df.merge(hustle_data[cols_to_merge],on=['PLAYER_ID'])\n",
    "\n",
    "\n",
    "    #drop empty rows (empty rows exist due to table formatting, not missing data)\n",
    "    player_stats_df.dropna(subset = ['PLAYER_NAME'], inplace = True)\n",
    "    \n",
    "    #there are cases of 2 repeated duplicates\n",
    "    #optional function do apply and correct the repeated columns\n",
    "    player_stats_df = player_stats_df.drop_duplicates(subset='PLAYER_ID', keep=\"first\")\n",
    "    #add a column to indicate if stats are for regular season or playoffs\n",
    "    player_stats_df.insert(1, \"Season\", season_type)\n",
    "    player_stats_df.insert(0, \"Year\", [year]*(len(player_stats_df.index)))\n",
    "    return player_stats_df\n",
    "\n",
    "\n",
    "def scrape_stats_history(start,end,league_id,season_segment):\n",
    "    \n",
    "    num_equals = 0\n",
    "    num_duplicate_index = 0\n",
    "    year_s,month_s,day_s = start.split(\"-\")\n",
    "\n",
    "    year_e,month_e,day_e = end.split(\"-\")\n",
    "    \n",
    "    year_s = int(year_s)\n",
    "    year_e = int(year_e)\n",
    "    # month_s = int(month_s)\n",
    "    # month_e = int(month_e)\n",
    "    # day_s = int(day_s)\n",
    "    # day_e = int(day_e)    \n",
    "    year_gap = year_e - year_s\n",
    "    year_list = list(range(year_s,year_e))\n",
    "\n",
    "    season_format_dict = {i: f'{i}-{(i%2000)+1}' for i in year_list}\n",
    "\n",
    "    all_player_stats_df = pd.DataFrame()\n",
    "    \n",
    "    for year in year_list:\n",
    "\n",
    "        reg_season_df = scrape_season(year,season_format_dict[year], league_id,'regular','game')\n",
    "        reg_season_df = reg_season_df.drop_duplicates(subset = ['PLAYER_ID'])\n",
    "        all_player_stats_df=pd.concat([all_player_stats_df,reg_season_df], ignore_index=True)\n",
    "\n",
    "        post_season_df = scrape_season(year,season_format_dict[year], league_id,'post','game')\n",
    "        post_season_df = post_season_df.drop_duplicates(subset = ['PLAYER_ID'])\n",
    "        all_player_stats_df=pd.concat([all_player_stats_df,post_season_df], ignore_index=True)    \n",
    "\n",
    "        print('Scraped {} regular and post season player stats'.format(year))\n",
    "\n",
    "    all_player_stats_df.to_csv(DIR_RAW_DATA+'players_stats.csv',index= False)\n",
    "    print('Scraped data saved into csv file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_stats_history(date_start,date_end,'00','game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats_df = pd.read_csv(DIR_RAW_DATA+'players_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inactive List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from requests import get\n",
    "\n",
    "headers = ({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) \\\n",
    "         AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "         Chrome/41.0.2228.0 Safari/537.36'\n",
    "})\n",
    "\n",
    "maxPages = 817\n",
    "\n",
    "def configScraper(pageNum):\n",
    "    url = f\"http://prosportstransactions.com/basketball/Search/SearchResults.php?Player=&Team=&BeginDate={date_start}&EndDate={date_end}&ILChkBx=yes&Submit=Search&start={pageNum}\"\n",
    "    response = get(url, headers=headers)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def scrapeInactiveList(numPages):\n",
    "    inactive_list_scraped_df = pd.DataFrame(columns = ['Date','Team','Acquired','Relinquished','Notes'])\n",
    "\n",
    "    for i in range(0,(maxPages-1)*25+1,25):\n",
    "        soup = configScraper(i)\n",
    "        table = soup.find_all('table',class_='datatable center')\n",
    "        table_rows = table[0].find_all('tr')\n",
    "        for k in range(1,len(table_rows)):\n",
    "            data = table_rows[k].find_all('td')\n",
    "            row_data = [data[0].text.strip(),data[1].text.strip(),data[2].text[2:].strip(),data[3].text[2:].strip(),data[4].text.strip()]\n",
    "            inactive_list_scraped_df.loc[len(inactive_list_scraped_df.index)] = row_data\n",
    "        print(f'Scraped page {int(i/25+1)}')\n",
    "        \n",
    "    inactive_list_scraped_df.to_csv(DIR_RAW_DATA+'inactive_list_scraped.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapeInactiveList(maxPages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Schedule\n",
    "\n",
    "**Observations**\n",
    "- The season year referes to the year where that season finishes, therefore if a season year is 2018 then it's refering to the season of 2017-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasons schedules to scrape\n",
    "season_list = ['2014','2015','2016','2017','2018','2019','2020','2021','2022']\n",
    "\n",
    "#NBA teams to scrape (this dictionary is valid (complete) for 2009-2019 seasons)\n",
    "team_dict = {\n",
    "    'ATL': 'Atlanta Hawks',\n",
    "    'BOS': 'Boston Celtics',\n",
    "    'BRK': 'Brooklyn Nets',\n",
    "    'CHA': 'Charlotte Bobcats',\n",
    "    'CHI': 'Chicago Bulls',\n",
    "    'CHO': 'Charlotte Hornets',\n",
    "    'CLE': 'Cleveland Cavaliers',\n",
    "    'DAL': 'Dallas Mavericks',\n",
    "    'DEN': 'Denver Nuggets',\n",
    "    'DET': 'Detroit Pistons',\n",
    "    'GSW': 'Golden State Warriors',\n",
    "    'HOU': 'Houston Rockets',\n",
    "    'IND': 'Indiana Pacers',\n",
    "    'LAC': 'Los Angeles Clippers',\n",
    "    'LAL': 'Los Angeles Lakers',\n",
    "    'MEM': 'Memphis Grizzlies',\n",
    "    'MIA': 'Miami Heat',\n",
    "    'MIL': 'Milwaukee Bucks',\n",
    "    'MIN': 'Minnesota Timberwolves',\n",
    "    'NJN': 'New Jersey Nets',\n",
    "    'NOH': 'New Orleans Hornets',\n",
    "    'NOP': 'New Orleans Pelicans',\n",
    "    'NYK': 'New York Knicks',\n",
    "    'OKC': 'Oklahoma City Thunder',\n",
    "    'ORL': 'Orlando Magic',\n",
    "    'PHI': 'Philadelphia 76ers',\n",
    "    'PHO': 'Phoenix Suns',\n",
    "    'POR': 'Portland Trailblazers',\n",
    "    'SAC': 'Sacramento Kings',\n",
    "    'SAS': 'San Antonio Spurs',\n",
    "    'TOR': 'Toronto Raptors',\n",
    "    'UTA': 'Utah Jazz',\n",
    "    'WAS': 'Washington Wizards'   \n",
    "}\n",
    "\n",
    "#teams that moved or otherwise had a name change - need to handle these teams separately (this dictionary is valid for 2009-2019)\n",
    "teams_relocate_rename_dict = {\n",
    "    # 'BRK': ['2014', '2015', '2016', '2017', '2018', '2019', '2020','2021','2022'],\n",
    "    'CHA': ['2014','2015'],\n",
    "    'CHO': ['2016', '2017', '2018', '2019', '2020','2021','2022'],\n",
    "    # 'NJN': ['2011', '2012', '2013'],\n",
    "    'NOH': ['2014'],\n",
    "    'NOP': ['2015', '2016', '2017', '2018', '2019', '2020','2021','2022'],\n",
    "}\n",
    "\n",
    "headers = ({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) \\\n",
    "         AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "         Chrome/41.0.2228.0 Safari/537.36'\n",
    "})\n",
    "\n",
    "def scrape_team_season_schedule(team_abrv,year,team_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function scrapes season schedules. It has three inputs: team_abrv (a string; i.e. 'POR'),a year (a string; i.e. '2017'),\n",
    "    and a dictionary containing team names; Output is a dataframe with schedule information.\n",
    "    \"\"\"\n",
    "    #website URL to scrape \n",
    "    url = \"https://www.basketball-reference.com/teams/{}/{}_games.html\". format(team_abrv,year)\n",
    "    response = get(url, headers=headers)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    \n",
    "    # use findALL() to get the column headers\n",
    "    soup.findAll('tr', limit=1)\n",
    "\n",
    "    #find all rows in table\n",
    "    rows = soup.findAll('tr')\n",
    "    sched_data = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
    "    #create a panda frame \n",
    "    sched_df = pd.DataFrame(sched_data)\n",
    "\n",
    "    #drop columns that aren't needed (keeping date, home/away, opponent, OT info)\n",
    "    sched_df.drop(columns = [1,2,3,6,8,9,10,11,12,13], inplace = True)\n",
    "    \n",
    "    #add column headers\n",
    "    sched_df.columns = ['Date','Away_flag','Opponent','OT_flag']\n",
    "\n",
    "    #drop empty rows (empty rows exist due to table formatting, not missing data)\n",
    "    sched_df.dropna(subset = ['Date'], inplace = True)\n",
    "\n",
    "    #add a column indicating the game number for a given season\n",
    "    sched_df.reset_index(inplace = True)\n",
    "    sched_df['Game_num'] = sched_df.index + 1\n",
    "\n",
    "    #add a column indicating the team\n",
    "    sched_df['Team'] = team_dict[team_abrv]\n",
    "\n",
    "    #add a column indicating the year in which the season begins\n",
    "    sched_df['Year'] = int(year)-1\n",
    "    \n",
    "    #reorder columns\n",
    "    sched_df = sched_df[['Team','Year', 'Game_num','Date','Away_flag','Opponent','OT_flag']]\n",
    "\n",
    "    return sched_df\n",
    "    \n",
    "def scrape_schedule(season_list,team_dict,teams_relocate_rename_dict):\n",
    "    all_teams_sched_df = pd.DataFrame()\n",
    "    for team in team_dict:\n",
    "        \n",
    "        team_sched_df = pd.DataFrame(columns = ['Team','Year','Game_num','Date','Away_flag','Opponent','OT_flag']) #create empty dataframe with column headers\n",
    "        \n",
    "        if team not in teams_relocate_rename_dict: #for those teams that didn't (a) change cities, or (b) otherwise have a name change\n",
    "            for year in season_list:\n",
    "                single_season_df = scrape_team_season_schedule(team, year,team_dict)\n",
    "                team_sched_df=pd.concat([team_sched_df,single_season_df], ignore_index=True)\n",
    "                print('Scraped {} {} game schedule'.format(team,year))\n",
    "                #Add a pause to keep web server happy\n",
    "                time.sleep(1)\n",
    "        \n",
    "            print('Scraped multi-season schedule - {} game schedule {} - {}'.format(team, season_list[0], season_list[-1]))\n",
    "\n",
    "        else:    \n",
    "            for year in teams_relocate_rename_dict[team]: #for those team that either moved or otherwise had a name change\n",
    "                single_season_df = scrape_team_season_schedule(team, year,team_dict)\n",
    "                team_sched_df=pd.concat([team_sched_df,single_season_df], ignore_index=True)\n",
    "                print('Scraped {} {} game schedule'.format(team,year))\n",
    "                #Add a pause to keep web server happy\n",
    "                time.sleep(1)\n",
    "            \n",
    "            print('Scraped multi-season schedule - {} game schedule {} - {}'.format(team, season_list[0], season_list[-1]))\n",
    "\n",
    "    #append 'master schedule' data frame with team's schedule\n",
    "        all_teams_sched_df = pd.concat([all_teams_sched_df, team_sched_df], ignore_index=True)   \n",
    "\n",
    "    year_s = int(season_list[0])-1\n",
    "    year_e = int(season_list[-1])-1\n",
    "\n",
    "    all_teams_sched_df.to_csv(DIR_RAW_DATA+'all_teams_schedule_{}_{}.csv'.format(str(year_s), str(year_e)))\n",
    "\n",
    "    return all_teams_sched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_sched_df = scrape_schedule(season_list,team_dict,teams_relocate_rename_dict)\n",
    "teams_sched_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d0e0863b4dbc785a2b1bd227b176323538a9cabeeaebcabf04a1216aba68dd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
